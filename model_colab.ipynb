{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saarthag/Qualcomm-AV-DL-Hackathon/blob/main/model_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/saarthag/Qualcomm-AV-DL-Hackathon.git"
      ],
      "metadata": {
        "id": "9Mu2EJXt9noj",
        "outputId": "d74ce945-8f72-46d9-d6bd-ac82a34feae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Qualcomm-AV-DL-Hackathon' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "1kTn-eSAnIov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision as tv\n",
        "from torchvision.io import decode_image\n",
        "from torchvision.transforms import v2\n",
        "from torchvision import models, tv_tensors\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "from tempfile import TemporaryDirectory"
      ],
      "metadata": {
        "id": "XoINL8OasKcn"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading and pre-processing"
      ],
      "metadata": {
        "id": "VYkap1Npnb8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Qualcomm-AV-DL-Hackathon/train.csv')\n",
        "# Split the [raw] data into training and validation splits\n",
        "train_df, validation_df = train_test_split(df, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "r3qupMrW6Mfq"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom dataset and dataloader to fetch and feed the data downstream"
      ],
      "metadata": {
        "id": "q5aCvvyEnpzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmergencyVehiclesDataset(Dataset):\n",
        "  def __init__(self, annotations_df: pd.DataFrame, img_dir: str,\n",
        "               transform=None):\n",
        "    self.img_labels = annotations_df\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      img_path = os.path.join(self.img_dir, self.img_labels.iat[idx, 0])\n",
        "      image = decode_image(img_path)\n",
        "      label = self.img_labels.iat[idx, 1]\n",
        "\n",
        "      if self.transform:\n",
        "        image = self.transform(image)\n",
        "\n",
        "      return tv_tensors.Image(image), label"
      ],
      "metadata": {
        "id": "5OlBiZ9ksTuP"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert an image to float32 (from uint8), and normalize it based on ImageNet's mean and stddev\n",
        "transform = v2.Compose([\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "jNiasJHvqXQC"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to create PyTorch DataLoader from a given DataFrame\n",
        "def get_loader(annotations_df: pd.DataFrame, batch_size: int=4, shuffle: bool=True):\n",
        "  dataset = EmergencyVehiclesDataset(\n",
        "      annotations_df=annotations_df,\n",
        "      img_dir='/content/Qualcomm-AV-DL-Hackathon/images/',\n",
        "      transform=transform)\n",
        "\n",
        "  return DataLoader(dataset, batch_size, shuffle), len(dataset)"
      ],
      "metadata": {
        "id": "BhacrFmPpk7n"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, train_set_size = get_loader(train_df)\n",
        "validation_loader, validation_set_size = get_loader(validation_df)"
      ],
      "metadata": {
        "id": "ZBAkk5sTl1g_"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the device - CUDA/CPU"
      ],
      "metadata": {
        "id": "G_ICIt2Hrfg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UyrY-pRgH9z",
        "outputId": "a6fc946a-0a5b-4210-e513-43108e40124d"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {'train': train_loader, 'val': validation_loader}\n",
        "dataset_sizes = {'train': train_set_size, 'val': validation_set_size}"
      ],
      "metadata": {
        "id": "P1tSp_jIg1Xl"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuring the base model for fine tuning\n",
        "Here, we use ResNet18 as the said base model"
      ],
      "metadata": {
        "id": "qeFky4DFvKTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18_base_model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# Reset the last fully connected layer of the model\n",
        "resnet18_base_model.fc = nn.Linear(resnet18_base_model.fc.in_features, 2)\n",
        "\n",
        "# Move the model to the selected device\n",
        "resnet18_base_model = resnet18_base_model.to(device)\n",
        "\n",
        "# Use Cross-Entropy as the loss function, and SGD optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet18_base_model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by 0.1 every 5 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
      ],
      "metadata": {
        "id": "HCrPAbvNkX4d"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base model fine-tuning (training)"
      ],
      "metadata": {
        "id": "PIOZNPRbsh8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model: nn.Module, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    start_ts = time.time()\n",
        "\n",
        "    # Create a temporary directory to save training checkpoints\n",
        "    with TemporaryDirectory() as tempdir:\n",
        "        print(\"Model checkpoints directory:\", tempdir)\n",
        "\n",
        "        best_checkpt_path = os.path.join(tempdir, 'best_checkpt.pt')\n",
        "        torch.save(model.state_dict(), best_checkpt_path)\n",
        "\n",
        "        # Best accuracy as produced by the model, across all epochs\n",
        "        best_acc = 0.\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'EPOCH {epoch+1}/{num_epochs}')\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                tot_loss = 0.\n",
        "                tot_hits = 0\n",
        "\n",
        "                # Iterate over data\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    # Zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # Forward propagation\n",
        "                    # Gradients are only calculated in the training phase\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        # torch.max returns the maximum probability across all classes\n",
        "                        # and the index at which it occurs, for all the samples in a batch\n",
        "                        # Since we are only interested in the class index, we store it\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # Backprop should occur only in the training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    tot_loss += loss.item() * inputs.size(0)\n",
        "                    # Total hits are all correct predictions by the model for this batch\n",
        "                    tot_hits += torch.sum(preds == labels.data)\n",
        "\n",
        "                # Adjust the learning rate\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = tot_loss / dataset_sizes[phase]\n",
        "                epoch_acc = tot_hits.double() / dataset_sizes[phase]\n",
        "\n",
        "                print(f'{phase} Loss: {epoch_loss:.5f} Acc: {epoch_acc:.5f}')\n",
        "\n",
        "                # Save the model if it outperforms its [own] best performing epoch so far\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    torch.save(model.state_dict(), best_checkpt_path)\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - start_ts\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best validation accuracy: {best_acc:4f}')\n",
        "\n",
        "        # Load best checkpoint\n",
        "        model.load_state_dict(torch.load(best_checkpt_path, weights_only=True))\n",
        "    return model"
      ],
      "metadata": {
        "id": "durGJa-5e_JK"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "resnet18_base_model = train_model(resnet18_base_model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "BDK67jP-pY-l",
        "outputId": "f219ad94-57ff-4c8c-9bd6-99063a48ea60"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoints directory: /tmp/tmp37qm9mh2\n",
            "EPOCH 1/25\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-136-561f33693949>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m resnet18_base_model = train_model(resnet18_base_model, criterion, optimizer, exp_lr_scheduler,\n\u001b[0m\u001b[1;32m      3\u001b[0m                        num_epochs=25)\n",
            "\u001b[0;32m<ipython-input-135-ebe51f50da2b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     45\u001b[0m                         \u001b[0;31m# Backprop should occur only in the training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "dnrYPDUnwkvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load a model saved previously for inference, since the training and inference may occur independently"
      ],
      "metadata": {
        "id": "3dwZ04vuwovz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment the following if you wish to load a different checkpoint file\n",
        "\n",
        "# resnet18_base_model.load_state_dict(torch.load('/content/best_checkpt.pt',\n",
        "#                                     weights_only=True, map_location=device))"
      ],
      "metadata": {
        "id": "qHQ3HLPW3sts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test data\n",
        "test_df = pd.read_csv('/content/Qualcomm-AV-DL-Hackathon/test_If1BZq3.csv')"
      ],
      "metadata": {
        "id": "DiufBkUs6mAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Can be optimized??\n",
        "def predict_for_model(model: nn.Module):\n",
        "  def predict(img_id):\n",
        "    img_path=f'/content/Qualcomm-AV-DL-Hackathon/images/{img_id}'\n",
        "    img = tv_tensors.Image(decode_image(img_path))\n",
        "    img = transform(img)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(img.unsqueeze(0))\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      return preds[0].item()\n",
        "\n",
        "  return predict"
      ],
      "metadata": {
        "id": "j6w4gvKWTKIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_fn = predict_for_model(resnet18_base_model)\n",
        "test_df['emergency_or_not']=test_df['image_names'].map(\n",
        "    predict_for_model(resnet18_base_model))"
      ],
      "metadata": {
        "id": "Dajw3BJAVDr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save inferences on test data"
      ],
      "metadata": {
        "id": "nbaRikHtyQS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('/content/test_If1BZq3.csv', index=False)"
      ],
      "metadata": {
        "id": "K-eNkF_gbGow"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}